// NOTE: This file has been auto-generated. Do not edit directly.

export default {
  model_type: "gpt_neox",
  models: [
    {
      model_id: "onnx-internal-testing/tiny-random-GPTNeoXForCausalLM-ONNX",
      dtype: "fp32",
      architectures: ["GPTNeoXForCausalLM"],
      ops: [
        "Add",
        "Cast",
        "Concat",
        "Constant",
        "ConstantOfShape",
        "Cos",
        "Div",
        "Equal",
        "Erf",
        "Expand",
        "Gather",
        "Greater",
        "Identity",
        "MatMul",
        "Mul",
        "Neg",
        "Pow",
        "Range",
        "ReduceMean",
        "Reshape",
        "ScatterND",
        "Shape",
        "Sin",
        "Slice",
        "Softmax",
        "Sqrt",
        "Sub",
        "Transpose",
        "Trilu",
        "Unsqueeze",
        "Where",
      ],
    },
    {
      model_id:
        "onnx-internal-testing/tiny-random-GPTNeoXForSequenceClassification-ONNX",
      dtype: "fp32",
      architectures: ["GPTNeoXForSequenceClassification"],
      ops: [
        "Add",
        "ArgMax",
        "Cast",
        "Concat",
        "Constant",
        "ConstantOfShape",
        "Cos",
        "Div",
        "Equal",
        "Erf",
        "Expand",
        "Flatten",
        "Gather",
        "Greater",
        "Identity",
        "MatMul",
        "Mod",
        "Mul",
        "Neg",
        "Pow",
        "Range",
        "ReduceMean",
        "Reshape",
        "ScatterND",
        "Shape",
        "Sin",
        "Slice",
        "Softmax",
        "Sqrt",
        "Sub",
        "Transpose",
        "Trilu",
        "Unsqueeze",
        "Where",
      ],
    },
  ],
};
