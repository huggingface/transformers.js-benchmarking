// NOTE: This file has been auto-generated. Do not edit directly.

export default {
  model_type: "markuplm",
  models: [
    {
      model_id:
        "onnx-internal-testing/tiny-random-MarkupLMForQuestionAnswering-ONNX",
      dtype: "fp32",
      architectures: ["MarkupLMForQuestionAnswering"],
      ops: [
        "Add",
        "Cast",
        "Concat",
        "Constant",
        "CumSum",
        "Div",
        "Equal",
        "Erf",
        "Gather",
        "Identity",
        "MatMul",
        "Mul",
        "Not",
        "Pow",
        "ReduceMean",
        "Relu",
        "Reshape",
        "Shape",
        "Softmax",
        "Split",
        "Sqrt",
        "Squeeze",
        "Sub",
        "Transpose",
        "Unsqueeze",
      ],
    },
    {
      model_id:
        "onnx-internal-testing/tiny-random-MarkupLMForSequenceClassification-ONNX",
      dtype: "fp32",
      architectures: ["MarkupLMForSequenceClassification"],
      ops: [
        "Add",
        "Cast",
        "Concat",
        "Constant",
        "CumSum",
        "Div",
        "Equal",
        "Erf",
        "Gather",
        "Gemm",
        "Identity",
        "MatMul",
        "Mul",
        "Not",
        "Pow",
        "ReduceMean",
        "Relu",
        "Reshape",
        "Shape",
        "Softmax",
        "Sqrt",
        "Sub",
        "Tanh",
        "Transpose",
        "Unsqueeze",
      ],
    },
    {
      model_id:
        "onnx-internal-testing/tiny-random-MarkupLMForTokenClassification-ONNX",
      dtype: "fp32",
      architectures: ["MarkupLMForTokenClassification"],
      ops: [
        "Add",
        "Cast",
        "Concat",
        "Constant",
        "CumSum",
        "Div",
        "Equal",
        "Erf",
        "Gather",
        "Identity",
        "MatMul",
        "Mul",
        "Not",
        "Pow",
        "ReduceMean",
        "Relu",
        "Reshape",
        "Shape",
        "Softmax",
        "Sqrt",
        "Sub",
        "Transpose",
        "Unsqueeze",
      ],
    },
  ],
};
