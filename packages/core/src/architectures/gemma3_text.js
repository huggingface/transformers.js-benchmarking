// NOTE: This file has been auto-generated. Do not edit directly.

export default {
  model_type: "gemma3_text",
  models: [
    {
      model_id: "onnx-community/gemma-3-1b-it-ONNX",
      dtype: "q4",
      architectures: ["Gemma3ForCausalLM"],
      ops: [
        "Add",
        "Cast",
        "Concat",
        "ConstantOfShape",
        "Cos",
        "Div",
        "Equal",
        "Expand",
        "Gather",
        "Greater",
        "MatMul",
        "MatMulNBits",
        "Max",
        "Mul",
        "Neg",
        "Pow",
        "Range",
        "ReduceMean",
        "Reshape",
        "ScatterND",
        "Shape",
        "Sin",
        "Slice",
        "Softmax",
        "Sqrt",
        "Sub",
        "Tanh",
        "Transpose",
        "Trilu",
        "Unsqueeze",
        "Where",
      ],
    },
    {
      model_id: "onnx-community/gemma-3-1b-it-ONNX",
      dtype: "bnb4",
      architectures: ["Gemma3ForCausalLM"],
      ops: [
        "Add",
        "Cast",
        "Concat",
        "ConstantOfShape",
        "Cos",
        "Div",
        "Equal",
        "Expand",
        "Gather",
        "Greater",
        "MatMul",
        "MatMulBnb4",
        "Max",
        "Mul",
        "Neg",
        "Pow",
        "Range",
        "ReduceMean",
        "Reshape",
        "ScatterND",
        "Shape",
        "Sin",
        "Slice",
        "Softmax",
        "Sqrt",
        "Sub",
        "Tanh",
        "Transpose",
        "Trilu",
        "Unsqueeze",
        "Where",
      ],
    },
    {
      model_id: "onnx-community/gemma-3-1b-it-ONNX",
      dtype: "quantized",
      architectures: ["Gemma3ForCausalLM"],
      ops: [
        "Add",
        "Cast",
        "Concat",
        "ConstantOfShape",
        "Cos",
        "DequantizeLinear",
        "Div",
        "DynamicQuantizeLinear",
        "Equal",
        "Expand",
        "Gather",
        "Greater",
        "MatMul",
        "MatMulInteger",
        "Max",
        "Mul",
        "Neg",
        "Pow",
        "Range",
        "ReduceMean",
        "Reshape",
        "ScatterND",
        "Shape",
        "Sin",
        "Slice",
        "Softmax",
        "Sqrt",
        "Sub",
        "Tanh",
        "Transpose",
        "Trilu",
        "Unsqueeze",
        "Where",
      ],
    },
    {
      model_id: "onnx-community/gemma-3-1b-it-ONNX",
      dtype: "fp32",
      architectures: ["Gemma3ForCausalLM"],
      ops: [
        "Add",
        "Cast",
        "Concat",
        "ConstantOfShape",
        "Cos",
        "Div",
        "Equal",
        "Expand",
        "Gather",
        "Greater",
        "MatMul",
        "Max",
        "Mul",
        "Neg",
        "Pow",
        "Range",
        "ReduceMean",
        "Reshape",
        "ScatterND",
        "Shape",
        "Sin",
        "Slice",
        "Softmax",
        "Sqrt",
        "Sub",
        "Tanh",
        "Transpose",
        "Trilu",
        "Unsqueeze",
        "Where",
      ],
    },
    {
      model_id: "onnx-community/gemma-3-1b-it-ONNX-GQA",
      dtype: "q4",
      architectures: ["Gemma3ForCausalLM"],
      ops: [
        "Cast",
        "Concat",
        "FastGelu",
        "Gather",
        "GroupQueryAttention",
        "MatMul",
        "MatMulNBits",
        "Mul",
        "ReduceSum",
        "Reshape",
        "RotaryEmbedding",
        "Shape",
        "SimplifiedLayerNormalization",
        "SkipSimplifiedLayerNormalization",
        "Sub",
        "Transpose",
        "Unsqueeze",
      ],
    },
    {
      model_id: "onnx-community/gemma-3-1b-it-ONNX-GQA",
      dtype: "bnb4",
      architectures: ["Gemma3ForCausalLM"],
      ops: [
        "Cast",
        "Concat",
        "FastGelu",
        "Gather",
        "GroupQueryAttention",
        "MatMul",
        "MatMulBnb4",
        "Mul",
        "ReduceSum",
        "Reshape",
        "RotaryEmbedding",
        "Shape",
        "SimplifiedLayerNormalization",
        "SkipSimplifiedLayerNormalization",
        "Sub",
        "Transpose",
        "Unsqueeze",
      ],
    },
    {
      model_id: "onnx-community/gemma-3-1b-it-ONNX-GQA",
      dtype: "quantized",
      architectures: ["Gemma3ForCausalLM"],
      ops: [
        "Cast",
        "Concat",
        "DequantizeLinear",
        "DynamicQuantizeLinear",
        "FastGelu",
        "Gather",
        "GroupQueryAttention",
        "MatMul",
        "MatMulInteger",
        "Mul",
        "ReduceSum",
        "Reshape",
        "RotaryEmbedding",
        "Shape",
        "SimplifiedLayerNormalization",
        "SkipSimplifiedLayerNormalization",
        "Sub",
        "Transpose",
        "Unsqueeze",
      ],
    },
    {
      model_id: "onnx-community/gemma-3-1b-it-ONNX-GQA",
      dtype: "fp32",
      architectures: ["Gemma3ForCausalLM"],
      ops: [
        "Cast",
        "Concat",
        "FastGelu",
        "Gather",
        "GroupQueryAttention",
        "MatMul",
        "Mul",
        "ReduceSum",
        "Reshape",
        "RotaryEmbedding",
        "Shape",
        "SimplifiedLayerNormalization",
        "SkipSimplifiedLayerNormalization",
        "Sub",
        "Transpose",
        "Unsqueeze",
      ],
    },
  ],
};
